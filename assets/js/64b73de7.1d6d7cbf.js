"use strict";(self.webpackChunkblksail_edu_github_io=self.webpackChunkblksail_edu_github_io||[]).push([[7297],{347:(e,n,i)=>{i.r(n),i.d(n,{assets:()=>r,contentTitle:()=>o,default:()=>h,frontMatter:()=>a,metadata:()=>s,toc:()=>c});const s=JSON.parse('{"id":"module/image_recognition","title":"Image Recognition","description":"The BlueROV2 is equipped with a forward-facing camera on a gimbal.","source":"@site/docs/3-module/3_image_recognition.mdx","sourceDirName":"3-module","slug":"/module/image_recognition","permalink":"/docs/module/image_recognition","draft":false,"unlisted":false,"editUrl":"https://github.com/blksail-edu/blksail-edu.github.io/tree/main/docs/3-module/3_image_recognition.mdx","tags":[],"version":"current","sidebarPosition":3,"frontMatter":{"sidebar_position":3},"sidebar":"tutorialSidebar","previous":{"title":"Control","permalink":"/docs/module/closed_loop_control"},"next":{"title":"Sensor-Driven Autonomy","permalink":"/docs/module/sensor_driven_autonomy"}}');var t=i(4848),l=i(8453);const a={sidebar_position:3},o="Image Recognition",r={},c=[{value:"OpenCV",id:"opencv",level:2},{value:"Installation",id:"installation",level:3},{value:"Reading Images",id:"reading-images",level:3},{value:"Reading Videos",id:"reading-videos",level:3},{value:"Drawing on Images",id:"drawing-on-images",level:3},{value:"Line Detection",id:"line-detection",level:2},{value:"Hough Transform",id:"hough-transform",level:3},{value:"Probabilistic Hough Transform",id:"probabilistic-hough-transform",level:3},{value:"Example",id:"example",level:3},{value:"April Tags",id:"april-tags",level:2},{value:"Installation",id:"installation-1",level:3},{value:"Example",id:"example-1",level:3},{value:"Problem set",id:"problem-set",level:2},{value:"Problem 1: Lane Detection",id:"problem-1-lane-detection",level:3},{value:"Problem 2: Lane Following",id:"problem-2-lane-following",level:3}];function d(e){const n={a:"a",admonition:"admonition",code:"code",h1:"h1",h2:"h2",h3:"h3",header:"header",img:"img",input:"input",li:"li",ol:"ol",p:"p",pre:"pre",ul:"ul",...(0,l.R)(),...e.components};return(0,t.jsxs)(t.Fragment,{children:[(0,t.jsx)(n.header,{children:(0,t.jsx)(n.h1,{id:"image-recognition",children:"Image Recognition"})}),"\n",(0,t.jsx)(n.p,{children:"The BlueROV2 is equipped with a forward-facing camera on a gimbal.\nWe will be using this camera to detect objects in the water."}),"\n",(0,t.jsx)(n.h2,{id:"opencv",children:"OpenCV"}),"\n",(0,t.jsxs)(n.p,{children:[(0,t.jsx)(n.a,{href:"https://opencv.org/",children:"OpenCV"})," is a library of programming functions mainly aimed at real-time computer vision.\nIt is open-source and free for commercial use.\nIt is written in C++ and has bindings for Python."]}),"\n",(0,t.jsx)(n.h3,{id:"installation",children:"Installation"}),"\n",(0,t.jsxs)(n.p,{children:["On the backseat computer, we will be using ",(0,t.jsx)(n.a,{href:"https://github.com/opencv/opencv-python",children:"OpenCV with Python"}),"."]}),"\n",(0,t.jsx)(n.p,{children:"Create a new virtual environment and install OpenCV:"}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-bash",children:"mkvirtualenv -p python3 bluecv\nworkon bluecv\npip install opencv-python-headless\n"})}),"\n",(0,t.jsxs)(n.p,{children:["Now, fork ",(0,t.jsx)(n.a,{href:"https://github.com/blksail-edu/cv-intro",children:"cv-intro"})," and clone it in the home directory.\nOpen the ",(0,t.jsx)(n.code,{children:"cv-intro"})," folder in VSCode."]}),"\n",(0,t.jsx)(n.p,{children:"Create a new Jupyter notebook:"}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-bash",children:"touch test.ipynb\n"})}),"\n",(0,t.jsx)(n.p,{children:"Open the file in VSCode and add the following code:"}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-python",children:"import cv2\nimport numpy as np\nimport matplotlib.pyplot as plt\n"})}),"\n",(0,t.jsx)(n.p,{children:"Run the code and make sure it works."}),"\n",(0,t.jsxs)(n.admonition,{type:"note",children:[(0,t.jsx)(n.p,{children:"If you get an error, make sure:"}),(0,t.jsxs)(n.ol,{children:["\n",(0,t.jsxs)(n.li,{children:["You are in the ",(0,t.jsx)(n.code,{children:"bluecv"})," virtual environment.\nVSCode should display the name of the virtual environment in top right corner of the Jupyter notebook."]}),"\n",(0,t.jsxs)(n.li,{children:["You installed all the dependencies.\nTry installing them with ",(0,t.jsx)(n.code,{children:"pip install [...]"}),".\nThis should be run in the virtual environment."]}),"\n"]})]}),"\n",(0,t.jsx)(n.h3,{id:"reading-images",children:"Reading Images"}),"\n",(0,t.jsxs)(n.p,{children:["To read an image, use the ",(0,t.jsx)(n.code,{children:"imread"})," function:"]}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-python",children:"img = cv2.imread('image.jpg')\n"})}),"\n",(0,t.jsxs)(n.p,{children:["The image is stored as a NumPy array.\nTo display the image, use the ",(0,t.jsx)(n.code,{children:"imshow"})," function:"]}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-python",children:"plt.imshow(img)\n"})}),"\n",(0,t.jsx)(n.h3,{id:"reading-videos",children:"Reading Videos"}),"\n",(0,t.jsxs)(n.p,{children:["To read a video, use the ",(0,t.jsx)(n.code,{children:"VideoCapture"})," function:"]}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-python",children:"cap = cv2.VideoCapture('video.mp4')\n"})}),"\n",(0,t.jsxs)(n.p,{children:["To read the video frame by frame, use the ",(0,t.jsx)(n.code,{children:"read"})," function:"]}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-python",children:"ret, frame = cap.read()\n"})}),"\n",(0,t.jsx)(n.h3,{id:"drawing-on-images",children:"Drawing on Images"}),"\n",(0,t.jsxs)(n.p,{children:["To draw a line on an image, use the ",(0,t.jsx)(n.code,{children:"line"})," function:"]}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-python",children:"cv2.line(img, (0, 0), (100, 100), (255, 0, 0), 5)\n"})}),"\n",(0,t.jsxs)(n.p,{children:["To draw a rectangle on an image, use the ",(0,t.jsx)(n.code,{children:"rectangle"})," function:"]}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-python",children:"cv2.rectangle(img, (0, 0), (100, 100), (0, 255, 0), 5)\n"})}),"\n",(0,t.jsxs)(n.p,{children:["To draw a circle on an image, use the ",(0,t.jsx)(n.code,{children:"circle"})," function:"]}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-python",children:"cv2.circle(img, (50, 50), 50, (0, 0, 255), 5)\n"})}),"\n",(0,t.jsxs)(n.p,{children:["To draw a polygon on an image, use the ",(0,t.jsx)(n.code,{children:"polylines"})," function:"]}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-python",children:"pts = np.array([[10, 5], [20, 30], [70, 20], [50, 10]], np.int32)\npts = pts.reshape((-1, 1, 2))\ncv2.polylines(img, [pts], True, (0, 255, 255), 5)\n"})}),"\n",(0,t.jsxs)(n.p,{children:["To draw text on an image, use the ",(0,t.jsx)(n.code,{children:"putText"})," function:"]}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-python",children:"cv2.putText(img, 'Hello World!', (0, 130), cv2.FONT_HERSHEY_SIMPLEX, 1, (255, 255, 255), 2, cv2.LINE_AA)\n"})}),"\n",(0,t.jsx)(n.admonition,{type:"tip",children:(0,t.jsxs)(n.p,{children:["Visualize the image using ",(0,t.jsx)(n.code,{children:"plt.imshow(img)"})," after each drawing operation to see the result."]})}),"\n",(0,t.jsx)(n.h2,{id:"line-detection",children:"Line Detection"}),"\n",(0,t.jsx)(n.h3,{id:"hough-transform",children:"Hough Transform"}),"\n",(0,t.jsxs)(n.p,{children:["The ",(0,t.jsx)(n.a,{href:"https://en.wikipedia.org/wiki/Hough_transform",children:"Hough transform"})," is a feature extraction technique used in image analysis, computer vision, and digital image processing.\nThe purpose of the technique is to find imperfect instances of objects within a certain class of shapes by a voting procedure."]}),"\n",(0,t.jsx)(n.h3,{id:"probabilistic-hough-transform",children:"Probabilistic Hough Transform"}),"\n",(0,t.jsxs)(n.p,{children:["The ",(0,t.jsx)(n.a,{href:"https://docs.opencv.org/3.4/d9/db0/tutorial_hough_lines.html",children:"probabilistic Hough transform"})," is an optimization of the Hough transform.\nIt is a straight line detection method.\nIt returns the start and end points of the detected lines."]}),"\n",(0,t.jsx)(n.h3,{id:"example",children:"Example"}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-python",children:"gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY) # convert to grayscale\nedges = cv2.Canny(gray, 50, 150, apertureSize=3) # detect edges\nlines = cv2.HoughLinesP(\n                edges,\n                1,\n                np.pi/180,\n                100,\n                minLineLength=100,\n                maxLineGap=10,\n        ) # detect lines\n\nfor line in lines:\n    x1, y1, x2, y2 = line[0]\n    cv2.line(img, (x1, y1), (x2, y2), (0, 255, 0), 2)\n\nplt.imshow(img)\n"})}),"\n",(0,t.jsx)(n.admonition,{title:"Check-Off",type:"warning",children:(0,t.jsxs)(n.ul,{className:"contains-task-list",children:["\n",(0,t.jsxs)(n.li,{className:"task-list-item",children:[(0,t.jsx)(n.input,{type:"checkbox",disabled:!0})," ","Run the code above and make sure it works."]}),"\n",(0,t.jsxs)(n.li,{className:"task-list-item",children:[(0,t.jsx)(n.input,{type:"checkbox",disabled:!0})," ","What do the parameters of the ",(0,t.jsx)(n.code,{children:"HoughLinesP"})," function do?"]}),"\n",(0,t.jsxs)(n.li,{className:"task-list-item",children:[(0,t.jsx)(n.input,{type:"checkbox",disabled:!0})," ","What happens if you change the parameters?"]}),"\n",(0,t.jsxs)(n.li,{className:"task-list-item",children:[(0,t.jsx)(n.input,{type:"checkbox",disabled:!0})," ","What happens if you change the ",(0,t.jsx)(n.code,{children:"minLineLength"})," and ",(0,t.jsx)(n.code,{children:"maxLineGap"})," parameters?"]}),"\n",(0,t.jsxs)(n.li,{className:"task-list-item",children:[(0,t.jsx)(n.input,{type:"checkbox",disabled:!0})," ","What happens if you change the ",(0,t.jsx)(n.code,{children:"apertureSize"})," parameter of the ",(0,t.jsx)(n.code,{children:"Canny"})," function?"]}),"\n",(0,t.jsxs)(n.li,{className:"task-list-item",children:[(0,t.jsx)(n.input,{type:"checkbox",disabled:!0})," ","What happens if you change the ",(0,t.jsx)(n.code,{children:"threshold1"})," and ",(0,t.jsx)(n.code,{children:"threshold2"})," parameters of the ",(0,t.jsx)(n.code,{children:"Canny"})," function?"]}),"\n",(0,t.jsxs)(n.li,{className:"task-list-item",children:[(0,t.jsx)(n.input,{type:"checkbox",disabled:!0})," ","Modify the code to detect pool lanes."]}),"\n"]})}),"\n",(0,t.jsx)(n.h2,{id:"april-tags",children:"April Tags"}),"\n",(0,t.jsxs)(n.p,{children:[(0,t.jsx)(n.a,{href:"https://april.eecs.umich.edu/software/apriltag.html",children:"AprilTags"})," are a type of fiducial marker.\nThey are designed to be easily detected by computer vision algorithms.\nThey are used in robotics for localization and navigation."]}),"\n",(0,t.jsx)(n.h3,{id:"installation-1",children:"Installation"}),"\n",(0,t.jsxs)(n.p,{children:["On the backseat computer, we will be using [Python bindings for the Apriltags 3 library by Duckietown](\n](",(0,t.jsx)(n.a,{href:"https://github.com/duckietown/lib-dt-apriltags",children:"https://github.com/duckietown/lib-dt-apriltags"}),")"]}),"\n",(0,t.jsx)(n.p,{children:"In the same virtual environment as before, install the library:"}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-bash",children:"pip install dt-apriltags\n"})}),"\n",(0,t.jsx)(n.h3,{id:"example-1",children:"Example"}),"\n",(0,t.jsx)(n.p,{children:(0,t.jsx)(n.img,{alt:"Example",src:i(7415).A+"",width:"640",height:"480"})}),"\n",(0,t.jsxs)(n.p,{children:["Download the image above and save it as ",(0,t.jsx)(n.code,{children:"test_image.png"}),".\nIn a terminal, run the following command:"]}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-bash",children:"wget https://blksail-edu.github.io/img/test_image.png\n"})}),"\n",(0,t.jsx)(n.p,{children:"Back in the Jupyter notebook, add the following code:"}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-python",children:"from dt_apriltags import Detector\n"})}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-python",children:"img = cv2.imread('test_image.png', cv2.IMREAD_GRAYSCALE)\n"})}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-python",children:"at_detector = Detector(families='tag36h11',\n                       nthreads=1,\n                       quad_decimate=1.0,\n                       quad_sigma=0.0,\n                       refine_edges=1,\n                       decode_sharpening=0.25,\n                       debug=0)\n"})}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-python",children:"tags = at_detector.detect(img, estimate_tag_pose=False, camera_params=None, tag_size=None)\n"})}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-python",children:"color_img = cv2.cvtColor(img, cv2.COLOR_GRAY2RGB)\n"})}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-python",children:"for tag in tags:\n    for idx in range(len(tag.corners)):\n        cv2.line(color_img, tuple(tag.corners[idx - 1, :].astype(int)), tuple(tag.corners[idx, :].astype(int)), (0, 255, 0))\n\n    cv2.putText(color_img, str(tag.tag_id),\n                org=(tag.corners[0, 0].astype(int) + 10, tag.corners[0, 1].astype(int) + 10),\n                fontFace=cv2.FONT_HERSHEY_SIMPLEX,\n                fontScale=0.8,\n                color=(0, 0, 255))\n"})}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-python",children:"plt.imshow(img)\n"})}),"\n",(0,t.jsx)(n.p,{children:"The result should look like this:"}),"\n",(0,t.jsx)(n.p,{children:(0,t.jsx)(n.img,{alt:"Result",src:i(8233).A+"",width:"548",height:"418"})}),"\n",(0,t.jsx)(n.admonition,{title:"Check-Off",type:"warning",children:(0,t.jsxs)(n.ul,{className:"contains-task-list",children:["\n",(0,t.jsxs)(n.li,{className:"task-list-item",children:[(0,t.jsx)(n.input,{type:"checkbox",disabled:!0})," ","Run the code above and make sure it works."]}),"\n",(0,t.jsxs)(n.li,{className:"task-list-item",children:[(0,t.jsx)(n.input,{type:"checkbox",disabled:!0})," ","What do the parameters of the ",(0,t.jsx)(n.code,{children:"Detector"})," function do?"]}),"\n",(0,t.jsxs)(n.li,{className:"task-list-item",children:[(0,t.jsx)(n.input,{type:"checkbox",disabled:!0})," ","What happens if you change the parameters?"]}),"\n",(0,t.jsxs)(n.li,{className:"task-list-item",children:[(0,t.jsx)(n.input,{type:"checkbox",disabled:!0})," ","What are ",(0,t.jsx)(n.code,{children:"families"}),"?"]}),"\n",(0,t.jsxs)(n.li,{className:"task-list-item",children:[(0,t.jsx)(n.input,{type:"checkbox",disabled:!0})," ","What does ",(0,t.jsx)(n.code,{children:"estimate_tag_pose"})," do?"]}),"\n",(0,t.jsxs)(n.li,{className:"task-list-item",children:[(0,t.jsx)(n.input,{type:"checkbox",disabled:!0})," ","What does ",(0,t.jsx)(n.code,{children:"camera_params"})," do?"]}),"\n",(0,t.jsxs)(n.li,{className:"task-list-item",children:[(0,t.jsx)(n.input,{type:"checkbox",disabled:!0})," ","What does ",(0,t.jsx)(n.code,{children:"tag_size"})," do?"]}),"\n",(0,t.jsxs)(n.li,{className:"task-list-item",children:[(0,t.jsx)(n.input,{type:"checkbox",disabled:!0})," ","The ",(0,t.jsx)(n.code,{children:"detect"})," function returns a list of tags.\nWhat information does each tag contain?"]}),"\n",(0,t.jsxs)(n.li,{className:"task-list-item",children:[(0,t.jsx)(n.input,{type:"checkbox",disabled:!0})," ","Modify the code to give the position and orientation of each tag."]}),"\n"]})}),"\n",(0,t.jsx)(n.h2,{id:"problem-set",children:"Problem set"}),"\n",(0,t.jsx)(n.h3,{id:"problem-1-lane-detection",children:"Problem 1: Lane Detection"}),"\n",(0,t.jsxs)(n.p,{children:["In a new file ",(0,t.jsx)(n.code,{children:"lane_detection.py"}),":"]}),"\n",(0,t.jsxs)(n.ol,{children:["\n",(0,t.jsxs)(n.li,{children:["\n",(0,t.jsxs)(n.p,{children:["Write a python function ",(0,t.jsx)(n.code,{children:"detect_lines"})," that takes an image as an input and returns a list of detected lines.\nThe function should take the following parameters:"]}),"\n",(0,t.jsxs)(n.ul,{children:["\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.code,{children:"img"}),": the image to process"]}),"\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.code,{children:"threshold1"}),": the first threshold for the Canny edge detector (default: 50)"]}),"\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.code,{children:"threshold2"}),": the second threshold for the Canny edge detector (default: 150)"]}),"\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.code,{children:"apertureSize"}),": the aperture size for the Sobel operator (default: 3)"]}),"\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.code,{children:"minLineLength"}),": the minimum length of a line (default: 100)"]}),"\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.code,{children:"maxLineGap"}),": the maximum gap between two points to be considered in the same line (default: 10)"]}),"\n"]}),"\n"]}),"\n",(0,t.jsxs)(n.li,{children:["\n",(0,t.jsxs)(n.p,{children:["Write a python function ",(0,t.jsx)(n.code,{children:"draw_lines"})," that takes an image and a list of lines as inputs and returns an image with the lines drawn on it.\nThe function should take the following parameters:"]}),"\n",(0,t.jsxs)(n.ul,{children:["\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.code,{children:"img"}),": the image to process"]}),"\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.code,{children:"lines"}),": the list of lines to draw"]}),"\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.code,{children:"color"}),": the color of the lines (default: (0, 255, 0))"]}),"\n"]}),"\n"]}),"\n",(0,t.jsxs)(n.li,{children:["\n",(0,t.jsxs)(n.p,{children:["Write a python function ",(0,t.jsx)(n.code,{children:"get_slopes_intercepts"})," that takes a list of lines as an input and returns a list of slopes and a list of intercepts.\nThe function should take the following parameters:"]}),"\n",(0,t.jsxs)(n.ul,{children:["\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.code,{children:"lines"}),": the list of lines to process"]}),"\n"]}),"\n",(0,t.jsx)(n.p,{children:"The function should return the following parameters:"}),"\n",(0,t.jsxs)(n.ul,{children:["\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.code,{children:"slopes"}),": the list of slopes"]}),"\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.code,{children:"intercepts"}),": the list of horizontal intercepts"]}),"\n"]}),"\n"]}),"\n",(0,t.jsxs)(n.li,{children:["\n",(0,t.jsxs)(n.p,{children:["Write a python function ",(0,t.jsx)(n.code,{children:"detect_lanes"})," that takes a list of lines as an input and returns a list of lanes.\nThe function should take the following parameters:"]}),"\n",(0,t.jsxs)(n.ul,{children:["\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.code,{children:"lines"}),": the list of lines to process"]}),"\n"]}),"\n",(0,t.jsx)(n.p,{children:"The function should return the following parameters:"}),"\n",(0,t.jsxs)(n.ul,{children:["\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.code,{children:"lanes"}),": the list of lanes"]}),"\n"]}),"\n",(0,t.jsx)(n.p,{children:"The function should do the following:"}),"\n",(0,t.jsxs)(n.ol,{children:["\n",(0,t.jsxs)(n.li,{children:["Get the slopes and intercepts of the lines using the ",(0,t.jsx)(n.code,{children:"get_slopes_intercepts"})," function."]}),"\n",(0,t.jsx)(n.li,{children:"Check if a pair of lines is a lane."}),"\n",(0,t.jsx)(n.li,{children:"Return the list of lanes. Each lane should be a list of two lines."}),"\n"]}),"\n"]}),"\n",(0,t.jsxs)(n.li,{children:["\n",(0,t.jsxs)(n.p,{children:["Write a python function ",(0,t.jsx)(n.code,{children:"draw_lanes"})," that takes an image and a list of lanes as inputs and returns an image with the lanes drawn on it. Each lane should be a different color.\nThe function should take the following parameters:"]}),"\n",(0,t.jsxs)(n.ul,{children:["\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.code,{children:"img"}),": the image to process"]}),"\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.code,{children:"lanes"}),": the list of lanes to draw"]}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,t.jsx)(n.p,{children:"Test your code with the following image:"}),"\n",(0,t.jsx)(n.p,{children:(0,t.jsx)(n.img,{alt:"Lanes",src:i(3392).A+"",width:"3824",height:"2138"})}),"\n",(0,t.jsx)(n.admonition,{type:"note",children:(0,t.jsxs)(n.p,{children:["Create a new Jupyter notebook ",(0,t.jsx)(n.code,{children:"lane_detection.ipynb"})," and test your code."]})}),"\n",(0,t.jsx)(n.h3,{id:"problem-2-lane-following",children:"Problem 2: Lane Following"}),"\n",(0,t.jsxs)(n.p,{children:["In a new file ",(0,t.jsx)(n.code,{children:"lane_following.py"}),":"]}),"\n",(0,t.jsxs)(n.ol,{children:["\n",(0,t.jsxs)(n.li,{children:["\n",(0,t.jsxs)(n.p,{children:["Write a python function ",(0,t.jsx)(n.code,{children:"get_lane_center"})," that takes a list of lanes as an input and returns the intercept and slope of the closest lane.\nThe function should take the following parameters:"]}),"\n",(0,t.jsxs)(n.ul,{children:["\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.code,{children:"lanes"}),": the list of lanes to process"]}),"\n"]}),"\n",(0,t.jsx)(n.p,{children:"The function should return the following parameters:"}),"\n",(0,t.jsxs)(n.ul,{children:["\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.code,{children:"center_intercept"}),": the horizontal intercept of the center of the closest lane"]}),"\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.code,{children:"center_slope"}),": the slope of the closest lane"]}),"\n"]}),"\n",(0,t.jsx)(n.p,{children:"The function should use the functions written in the previous problem set."}),"\n"]}),"\n",(0,t.jsxs)(n.li,{children:["\n",(0,t.jsxs)(n.p,{children:["Write a python function ",(0,t.jsx)(n.code,{children:"recommend_direction"})," that takes the center of the closest lane and its slope as inputs and returns a direction.\nThe function should take the following parameters:"]}),"\n",(0,t.jsxs)(n.ul,{children:["\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.code,{children:"center"}),": the center of the closest lane"]}),"\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.code,{children:"slope"}),": the slope of the closest lane"]}),"\n"]}),"\n",(0,t.jsx)(n.p,{children:"The function should return the following parameters:"}),"\n",(0,t.jsxs)(n.ul,{children:["\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.code,{children:"direction"}),": the recommended direction"]}),"\n"]}),"\n",(0,t.jsx)(n.p,{children:"The function should do the following:"}),"\n",(0,t.jsxs)(n.ol,{children:["\n",(0,t.jsxs)(n.li,{children:["If the center is on the left of the image, return ",(0,t.jsx)(n.code,{children:"left"}),"."]}),"\n",(0,t.jsxs)(n.li,{children:["If the center is on the right of the image, return ",(0,t.jsx)(n.code,{children:"right"}),"."]}),"\n",(0,t.jsxs)(n.li,{children:["If the center is in the middle of the image, return ",(0,t.jsx)(n.code,{children:"forward"}),"."]}),"\n"]}),"\n"]}),"\n"]})]})}function h(e={}){const{wrapper:n}={...(0,l.R)(),...e.components};return n?(0,t.jsx)(n,{...e,children:(0,t.jsx)(d,{...e})}):d(e)}},3392:(e,n,i)=>{i.d(n,{A:()=>s});const s=i.p+"assets/images/lanes-15b8289a06a1b1e8a17347ad29bb1988.png"},7415:(e,n,i)=>{i.d(n,{A:()=>s});const s=i.p+"assets/images/test_image-727d17aa68a029a9a5f6101d37c15dfd.png"},8233:(e,n,i)=>{i.d(n,{A:()=>s});const s=i.p+"assets/images/apriltags_detected-26139bd3bf25abbbdc48c35b5613e83e.png"},8453:(e,n,i)=>{i.d(n,{R:()=>a,x:()=>o});var s=i(6540);const t={},l=s.createContext(t);function a(e){const n=s.useContext(l);return s.useMemo(function(){return"function"==typeof e?e(n):{...n,...e}},[n,e])}function o(e){let n;return n=e.disableParentContext?"function"==typeof e.components?e.components(t):e.components||t:a(e.components),s.createElement(l.Provider,{value:n},e.children)}}}]);